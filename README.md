# Word2Vec
Word2Vec, or "Word to Vector," is a popular and influential word embedding model used in NLP. It is designed to convert words or phrases into numerical vectors (vectors of real numbers) in such a way that the vectors capture semantic and contextual information about the words. These vectors are often used as word representations in various NLP tasks
#In this module I have shown just a simple implementation of the CBOW(Continuout Bag of Words) architecture.
